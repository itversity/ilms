{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "As part of this section we will primarily understand different ways to get started with Postgres.\n",
    "* Connecting to Database\n",
    "* Using psql\n",
    "* Setup SQL Workbench\n",
    "* SQL Workbench and Postgres\n",
    "* SQL Workbench Features\n",
    "* Setup Postgres using Docker\n",
    "* Data Loading Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Database\n",
    "\n",
    "We will be using JupyterHub based environment to master Postgresql. Let us go through the steps involved to get started using JupyterHub environment.\n",
    "* We will use Python Kernel with sql magic command and for that we need to first load the sql extension.\n",
    "* Create environment variable `DATABASE_URL` using SQL Alchemy format.\n",
    "* Write a simple query to get data from information schema table to validate database connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATABASE_URL=postgresql://training:itversity!23@localhost:5432/training_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM information_schema.tables LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using psql\n",
    "\n",
    "Let us understand how to use `psql` utility to perform database operations.\n",
    "* We need to have at least Postgres Client installed on the server from which you want to use psql to connect to Postgres Server.\n",
    "* If you are on the server where **Postgres Database Server** is installed, `psql` will be automatically available.\n",
    "* We can run `sudo -u postgres psql -U postgres` from the server provided you have sudo permissions on the server. Otherwise we need to go with `psql -U postgres -W` which will prompt for the password.\n",
    "* **postgres** is the super user for the postgres server and hence typically developers will not have access to it in non development environments.\n",
    "* As a developer, we can use following command to connect to a database setup on postgres server using user credentials.\n",
    "\n",
    "```shell\n",
    "psql -U sms_user -h <host_ip_or_dns_alias> -d <db_name> -W\n",
    "```\n",
    "* We typically use `psql` to troubleshoot the issues in non development servers. IDEs such as **SQL Alchemy** might be better for regular usage as part of development and unit testing process.\n",
    "* For this course, we will be primarily using Jupyter based environment for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup SQL Workbench\n",
    "\n",
    "Let us understand how to setup and use SQL Workbench.\n",
    "\n",
    "**Why SQL Workbench**\n",
    "\n",
    "Let us see the details why we might have to use SQL Workbench.\n",
    "* Using Database CLIs such psql for postgres, mysql etc can be cumbersome for those who are not comfortable with command line interfaces.\n",
    "* Database IDEs such as SQL Workbench will provide required features to run queries against databases with out worrying to much about underlying data dictionaries.\n",
    "* SQL Workbench provide required features to review databases and objects with out writing queries or running database specific commands.\n",
    "* Also Database IDEs provide capabilities to preserve the scripts we develop.\n",
    "> **In short Database IDEs such as SQL Workbench improves productivity.**\n",
    "\n",
    "**Alternative IDEs**\n",
    "\n",
    "There are several IDEs in the market.\n",
    "* TOAD\n",
    "* SQL Developer for Oracle\n",
    "* MySQL Workbench\n",
    "and many others\n",
    "\n",
    "**Install Workbench**\n",
    "\n",
    "Here are the instructions to setup SQL Workbench.\n",
    "* Download SQL Workbench (typically zip file)\n",
    "* Unzip and launch\n",
    "\n",
    "Once installed we need to perform below steps which will be covered in detail as part of next topic.\n",
    "* Download JDBC driver for the database we would like to connect.\n",
    "* Get the database connectivity information and connect to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Workbench and Postgres\n",
    "\n",
    "Let us connect to Postgres Database using SQL Workbench.\n",
    "\n",
    "* We are trying to connect to Postgres Database that is running as part of Docker container running in a Ubuntu 18.04 VM provisioned from GCP.\n",
    "* We have published Postgres database port to port 5433 on Ubuntu 18.04 VM.\n",
    "* We typically use ODBC or JDBC to connect to a Database from remote machines (our PC).\n",
    "* Here are the pre-requisites to connect to a Database on GCP.\n",
    "  * Make sure 5433 port is opened as part of the firewalls.\n",
    "  * If you have telnet configured on your system on which SQL Workbench is installed, make sure to validate by running telnet command using ip or DNS Alias and port number 5433.\n",
    "  * Ensure that you have downloaded right JDBC Driver for Postgres.\n",
    "  * Make sure to have right credentials (username and password).\n",
    "  * Ensure that you have database created on which the user have permissions.\n",
    "* You can validate credentials and permissions to the database by installing postgres client on Ubuntu 18.04 VM and then by connecting to the database using the credentials.\n",
    "* Once you have all the information required along with JDBC jar, ensure to save the information as part of the profile. You can also validate before saving the details by using **Test** option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Workbench Features\n",
    "\n",
    "Here are some of the key features, you have to familiar with related to SQL Workbench.\n",
    "* Saving profiles to connect to multiple databases.\n",
    "* Develop SQL files and preserve them for future usage.\n",
    "* Access data dictionary or information schema to validate tables, columns, sequences, indexes, constraints etc.\n",
    "* Generate scripts out of existing data.\n",
    "* Ability to manage database objects with out writing any commands. We can drop tables, indexes, sequences etc by right clicking and then dropping.\n",
    "\n",
    "Almost all leading IDEs provide all these features in similar fashion.\n",
    "\n",
    "**Usage Scenarios**\n",
    "\n",
    "Here are **some of the usage scenarios** for database IDEs such as SQL Workbench as part of day to day responsibilities.\n",
    "* Developers for generating and validating data as part of unit testing.\n",
    "* Testers to validate data for their test cases.\n",
    "* Business Analysts and Data Analysts to run ad hoc queries to understand the data better.\n",
    "* Developers to troubleshoot data related production issues using read only accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Postgres using Docker\n",
    "\n",
    "In some cases you might want to have postgres setup on your machine. Let us understand how we can setup Postgres using Docker.\n",
    "\n",
    "* If you are using Windows or Mac, ensure that you have installed Docker Desktop.\n",
    "* If you are using Ubuntu based desktop, make sure to setup Docker.\n",
    "* Here are the steps that can be used to setup Postgres database using Docker.\n",
    "  * Pull the postgres image using `docker pull`\n",
    "  * Create the container using `docker create`.\n",
    "  * Start the container using `docker start`.\n",
    "  * Alternatively we can use `docker run` which will pull, create and start the container.\n",
    "  * Use `docker logs` or `docker logs -f` to review the logs to ensure Postgres Server is up and running.\n",
    "\n",
    "```shell\n",
    "docker pull postgres\n",
    "\n",
    "docker container create \\\n",
    "  --name itv_pg \\\n",
    "  -p 5433:5432 \\\n",
    "  -h itv_pg \\\n",
    "  -e POSTGRES_PASSWORD=itversity \\\n",
    "  postgres\n",
    "\n",
    "docker start itv_pg\n",
    "\n",
    "docker logs itv_pg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Utilities\n",
    "\n",
    "Let us understand how we can load the data into databases using utilities provided.\n",
    "* Most of the databases provide data loading utilities.\n",
    "* One of the most common way of getting data into database tables is by using data loading utilities provided by the underlying datatabase technology.\n",
    "* We can load delimited files into database using these utilities.\n",
    "* Here are the steps we can follow to load the delimited data into the table.\n",
    "  * Make sure files are available on the server from which we are trying to load.\n",
    "  * Ensure the database and table are created for the data to be loaded.\n",
    "  * Run relevant command to load the data into the table.\n",
    "  * Make sure to validate by running queries.\n",
    "* Let us see a demo by loading a sample file into the table in Postgres database. The performance will be better if the files are loaded from the server directly.\n",
    "\n",
    "### Using COPY Command\n",
    "We can use COPY Command using `psql` to copy the data into the table.\n",
    "* Make sure database is created along with the user with right permissions. Also the user who want to use `COPY` command need to have pg_read_server_files role assigned.\n",
    "\n",
    "```shell\n",
    "docker exec -it itv_pg psql -U postgres\n",
    "```\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE itversity_sms_db;\n",
    "CREATE USER itversity_sms_user WITH PASSWORD 'sms_password';\n",
    "GRANT ALL ON DATABASE itversity_sms_db TO itversity_sms_user;\n",
    "GRANT pg_read_server_files TO itversity_sms_user;\n",
    "```\n",
    "\n",
    "* Exit and connect as non system user created.\n",
    "\n",
    "```shell\n",
    "psql -U itversity_sms_user \\\n",
    "  -h localhost \\\n",
    "  -p 5433 \\\n",
    "  -d itversity_sms_db \\\n",
    "  -W\n",
    "```\n",
    "\n",
    "* Create the `users` table.\n",
    "\n",
    "```sql\n",
    "CREATE TABLE users (\n",
    "  user_id SERIAL PRIMARY KEY,\n",
    "  user_first_name VARCHAR(30) NOT NULL,\n",
    "  user_last_name VARCHAR(30) NOT NULL,\n",
    "  user_email_id VARCHAR(50) NOT NULL,\n",
    "  user_email_validated BOOLEAN DEFAULT FALSE,\n",
    "  user_password VARCHAR(200),\n",
    "  user_role VARCHAR(1) NOT NULL DEFAULT 'U', --U and A\n",
    "  is_active BOOLEAN DEFAULT FALSE,\n",
    "  created_dt DATE DEFAULT CURRENT_DATE\n",
    ");\n",
    "```\n",
    "\n",
    "* Create the file with sample data. In this case data is added to users.csv under **~/sms_db**.\n",
    "\n",
    "```text\n",
    "user_first_name,user_last_name,user_email_id,user_role,created_dt\n",
    "Gordan,Bradock,gbradock0@barnesandnoble.com,A,2020-01-10\n",
    "Tobe,Lyness,tlyness1@paginegialle.it,U,2020-02-10\n",
    "Addie,Mesias,amesias2@twitpic.com,U,2020-03-05\n",
    "Corene,Kohrsen,ckohrsen3@buzzfeed.com,U,2020-04-15\n",
    "Darill,Halsall,dhalsall4@intel.com,U,2020-10-10\n",
    "```\n",
    "\n",
    "* Copy the files onto the server. In this case it is running in docker container.\n",
    "\n",
    "```shell\n",
    "docker cp users.csv itv_pg:/tmp\n",
    "```\n",
    "\n",
    "* Use copy command to load the data\n",
    "\n",
    "```shell\n",
    "COPY users(user_first_name, user_last_name, user_email_id, user_role, created_dt)\n",
    "FROM '/tmp/users.csv'\n",
    "DELIMITER ','\n",
    "CSV HEADER;\n",
    "```\n",
    "\n",
    "* Validate by running queries\n",
    "\n",
    "```sql\n",
    "SELECT * FROM users;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
